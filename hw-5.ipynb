{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scene Categorization\n",
    "\n",
    "The goal of this assignment is to introduce you to image categorization. We will focus on the task of scene categorization. You task is to implement image features, train a classifier using the training samples, and then evaluate the the classifier on the test set.\n",
    "\n",
    "\n",
    "Dataset: In the supplemental material, we have supplied images with 8 outdoor scene categories: coast, mountain, forest, open country, street, inside city, tall buildings and highways. The dataset has been split into a train set (1888 images) and test set (800 images), placed in train and test folders separately. The associated labels are stored in `gs.mat`, for example, label id of `42.jpg` in the training folder corresponds to `train_gs(42)`. Its actual label name will be `names{train_gs(42)}`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import re\n",
    "import time\n",
    "from imageio import imread\n",
    "from skimage.transform import resize\n",
    "from pathlib import Path\n",
    "from scipy.io import loadmat\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.cluster import KMeans,MiniBatchKMeans\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.neighbors import KDTree, KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.applications import *\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_sort(value):\n",
    "    numbers = re.compile(r'(\\d+)')\n",
    "    value = str(value)\n",
    "    parts = numbers.split(value)\n",
    "    parts[1::2] = map(int, parts[1::2])\n",
    "    return parts\n",
    "\n",
    "def get_images():\n",
    "    train_path = Path('./data/train')\n",
    "    test_path = Path('./data/test')\n",
    "    X_train = []\n",
    "    X_test = []\n",
    "    for image_path in sorted(train_path.glob('*.jpg'),key=numerical_sort):\n",
    "        image = imread(image_path)\n",
    "        X_train.append(image)\n",
    "    for image_path in sorted(test_path.glob('*.jpg'),key=numerical_sort):\n",
    "        image = imread(image_path)\n",
    "        X_test.append(image)\n",
    "    X_train = np.array(X_train)\n",
    "    X_test = np.array(X_test)\n",
    "    return X_train,X_test\n",
    "\n",
    "def get_labels():\n",
    "    label_path = Path('./data/gs.mat')\n",
    "    labels = loadmat(label_path)\n",
    "    y_train = labels['train_gs'].flatten()\n",
    "    y_test = labels['test_gs'].flatten()\n",
    "    return y_train,y_test\n",
    "\n",
    "def histogram_distance(h1,h2):\n",
    "    h1 = h1.astype(np.float32)\n",
    "    h2 = h2.astype(np.float32)\n",
    "    method = cv2.HISTCMP_INTERSECT\n",
    "    return cv2.compareHist(h1,h2,method)\n",
    "\n",
    "def get_scores(model,X_train,y_train,X_test,y_test):\n",
    "    yhat = model.predict(X_train)\n",
    "    score = accuracy_score(y_train,yhat)\n",
    "    print('Training Accuracy: %f' % round(score,3))    \n",
    "    yhat = model.predict(X_test)\n",
    "    score = accuracy_score(y_test,yhat)\n",
    "    print('Test Accuracy: %f' % round(score,3))\n",
    "    print('Confusion Matrix:\\n', confusion_matrix(y_test,yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data size: (1888, 256, 256, 3)\n",
      "test data size: (800, 256, 256, 3)\n",
      "training label size: (1888,)\n",
      "test label size: (800,)\n"
     ]
    }
   ],
   "source": [
    "X_train,X_test = get_images()\n",
    "print('training data size:',X_train.shape)\n",
    "print('test data size:',X_test.shape)\n",
    "\n",
    "y_train,y_test = get_labels()\n",
    "print('training label size:',y_train.shape)\n",
    "print('test label size:',y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Color histogram and kNN classifier\n",
    "\n",
    "Implement a function to compute the color histogram of an image. For example, you can use the Matlab function hist for computing marginal histogram of RGB channels.\n",
    "\n",
    "Use nearest neighbor classifier (kNN) to categorize the test images.\n",
    "\n",
    "- Describe your quantization/binning method and parameters\n",
    "- Report number of K for the kNN classifer\n",
    "- Display the confusion matrix and categorization accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_color_hists(X_train,X_test,bins=10):\n",
    "    X_train_hist = np.zeros((len(X_train),bins*3))\n",
    "    X_test_hist = np.zeros((len(X_test),bins*3))\n",
    "    for i in range(len(X_train)):\n",
    "        red = cv2.calcHist([X_train[i,:,:,0]],[0],None,[bins],[0,256]).flatten()\n",
    "        green = cv2.calcHist([X_train[i,:,:,1]],[0],None,[bins],[0,256]).flatten()\n",
    "        blue = cv2.calcHist([X_train[i,:,:,2]],[0],None,[bins],[0,256]).flatten()\n",
    "        X_train_hist[i] = np.concatenate([red,green,blue])\n",
    "    for i in range(len(X_test)):\n",
    "        red = cv2.calcHist([X_test[i,:,:,0]],[0],None,[bins],[0,256]).flatten()\n",
    "        green = cv2.calcHist([X_test[i,:,:,1]],[0],None,[bins],[0,256]).flatten()\n",
    "        blue = cv2.calcHist([X_test[i,:,:,2]],[0],None,[bins],[0,256]).flatten()\n",
    "        X_test_hist[i] = np.concatenate([red,green,blue])\n",
    "    return X_train_hist,X_test_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_hist,X_test_hist = get_color_hists(X_train,X_test,bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.560000\n",
      "Test Accuracy: 0.475000\n",
      "Confusion Matrix:\n",
      " [[30 16  3 19  8 10  4 10]\n",
      " [ 3 81  0  7  2  1  3  3]\n",
      " [ 9  4 58  7  5  6  6  5]\n",
      " [ 4 25  1 45  4  2 13  6]\n",
      " [16 14  2  9 34  6  3 16]\n",
      " [ 5 28  3 11  4 32  7 10]\n",
      " [ 1  9  0 10  5  1 68  6]\n",
      " [11  9  0 17 13  9  9 32]]\n"
     ]
    }
   ],
   "source": [
    "model = KNeighborsClassifier(n_neighbors=10,n_jobs=-1)\n",
    "model.fit(X_train_hist,y_train)\n",
    "get_scores(model,X_train_hist,y_train,X_test_hist,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of visual words model and nearest neighbor classifier\n",
    "\n",
    "Implement K-means cluster algorithm to compute visual word dictionary. The feature dimension of SIFT features is 128.\n",
    "\n",
    "Use the included SIFT word descriptors included in `sift_desc.mat` to build bag of visual words as your image representation.\n",
    "\n",
    "Use nearest neighbor classifier (kNN) to categorize the test images.\n",
    "\n",
    "- Describe the number of visual words you use, K-means stopping criterion, and the categorization accuracy.\n",
    "- Display the confusion matrix and categorization accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sift():\n",
    "    sift_path = Path('./data/sift_desc.mat')\n",
    "    sift = loadmat(sift_path)\n",
    "    train = sift['train_D'].flatten()\n",
    "    test = sift['test_D'].flatten()\n",
    "    train_sifts = [t.T for t in train]\n",
    "    test_sifts = [t.T for t in test]\n",
    "    return train_sifts,test_sifts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sifts,test_sifts = get_sift()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class K_Means:\n",
    "    def __init__(self, n_clusters, max_iters=1000):\n",
    "        self.n_clusters = n_clusters\n",
    "        self.centroids = None\n",
    "        self.labels = None\n",
    "        self.max_iters = max_iters\n",
    "\n",
    "    def fit(self, X):\n",
    "        mins = X.min()\n",
    "        maxs = X.max()\n",
    "        self.centroids = np.zeros((self.n_clusters, X.shape[1]))\n",
    "        for idx, col in enumerate(X.T):\n",
    "            col_min, col_max = np.min(col), np.max(col)\n",
    "            for k in range(self.n_clusters):\n",
    "                self.centroids[k, idx] = np.random.uniform(col_min, col_max, size=(1))\n",
    "        self.labels = np.random.random_integers(low=0, high=self.n_clusters - 1, size=(X.shape[0]))\n",
    "        for i in range(self.max_iters):\n",
    "            print(f\"Iteration {i}\")\n",
    "            changed = 0\n",
    "            distances = self.get_distances(X)\n",
    "            groups = {key: [] for key in range(self.n_clusters)}\n",
    "            for idx, feat in enumerate(X):\n",
    "                closest = distances[idx].argmin()\n",
    "                if self.labels[idx] != closest:\n",
    "                    self.labels[idx] = closest\n",
    "                    changed += 1\n",
    "                groups[closest].append(feat)\n",
    "            for group in sorted(groups):\n",
    "                group_feats = groups[group]\n",
    "                if len(group_feats):\n",
    "                    self.centroids[group] = np.mean(groups[group], axis=0)\n",
    "                else:\n",
    "                    self.centroids[group] = np.random.uniform(mins, maxs, size=(X.shape[1]))\n",
    "            if not changed:\n",
    "                break\n",
    "\n",
    "    def predict(self, x):\n",
    "        dist = self.get_distances(x)\n",
    "        preds = dist.argmin()\n",
    "        return preds\n",
    "    \n",
    "    def get_distances(self, X):\n",
    "        try:\n",
    "            p_squared = np.square(X).sum(axis=1)\n",
    "        except:\n",
    "            p_squared = np.square(X)\n",
    "        q_squared = np.square(self.centroids).sum(axis=1)\n",
    "        product   = -2*X.dot(self.centroids.T)\n",
    "        distances = np.sqrt(product+q_squared+np.matrix(p_squared).T)\n",
    "        return distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vis_bow(train_sifts,test_sifts,n_clusters=100):\n",
    "    stacked_train_sifts = np.vstack(train_sifts)\n",
    "    stacked_test_sifts = np.vstack(test_sifts)\n",
    "    kmeans = MiniBatchKMeans(n_clusters=n_clusters) # K_Means(n_clusters=n_clusters)\n",
    "    kmeans.fit(stacked_train_sifts)\n",
    "    train_clusters = [kmeans.predict(words) for words in train_sifts]\n",
    "    X_train_bow = np.array([np.bincount(words, minlength=n_clusters) for words in train_clusters])\n",
    "    test_clusters = [kmeans.predict(words) for words in test_sifts]\n",
    "    X_test_bow = np.array([np.bincount(words, minlength=n_clusters) for words in test_clusters])\n",
    "    return X_train_bow,X_test_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_bow,X_test_bow = vis_bow(train_sifts,test_sifts,n_clusters=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.635000\n",
      "Test Accuracy: 0.559000\n",
      "Confusion Matrix:\n",
      " [[60  1 18  0  6 12  2  1]\n",
      " [ 0 91  0  1  2  3  2  1]\n",
      " [19  2 51  3  7 10  4  4]\n",
      " [ 6  7  1 58  2  4 13  9]\n",
      " [ 7  6  3  1 60 15  6  2]\n",
      " [31  7  3  2 10 41  2  4]\n",
      " [ 2 10  1  9 11 13 50  4]\n",
      " [11  6  5 15 12  6  9 36]]\n"
     ]
    }
   ],
   "source": [
    "model = KNeighborsClassifier(n_neighbors=15,n_jobs=-1)\n",
    "model.fit(X_train_bow,y_train)\n",
    "get_scores(model,X_train_bow,y_train,X_test_bow,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of visual words model and a discriminative classifier\n",
    "\n",
    "Use the bag of visual word representation.\n",
    "\n",
    "Replace the nearest neighbor classifier with SVM classifer. Use 1 vs. all SVM for training the multi-class classifier.\n",
    "\n",
    "- Report the training time and testing time for SVM\n",
    "- Display the confusion matrix and categorization accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training time: 0.767 seconds\n",
      "Training Accuracy: 0.707000\n",
      "Test Accuracy: 0.615000\n",
      "Confusion Matrix:\n",
      " [[68  0  8  0 10 12  1  1]\n",
      " [ 0 84  0  0  7  3  4  2]\n",
      " [37  0 32  4  8  9  4  6]\n",
      " [ 2  4  1 65  1  7  6 14]\n",
      " [ 4  2  1  0 67 18  8  0]\n",
      " [21  3  1  2 12 57  1  3]\n",
      " [ 2  7  0  8 14  5 57  7]\n",
      " [ 0  1  4 13  7  7  6 62]]\n",
      "testing time: 0.314 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.clock()\n",
    "model = SVC(C=.001,kernel='linear')\n",
    "model.fit(X_train_bow,y_train)\n",
    "end = time.clock()\n",
    "print('training time:',round(end-start,3),'seconds')\n",
    "\n",
    "start = time.clock()\n",
    "get_scores(model,X_train_bow,y_train,X_test_bow,y_test)\n",
    "end = time.clock()\n",
    "print('testing time:',round(end-start,3),'seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN model and a discriminative classifier\n",
    "\n",
    "Using pre-trained convolutional neural network as a feature extractor and a SVM for scene categorization. You can use the ConvNet library in MATLAB MatConvNet with one of the pre-trained classification models here.\n",
    "\n",
    "Use 1 vs. all SVM classifier to categorize the test images\n",
    "\n",
    "- Describe the model you used.\n",
    "- Display the confusion matrix and categorization accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1888/1888 [==============================] - 624s 331ms/step\n",
      "800/800 [==============================] - 259s 324ms/step\n"
     ]
    }
   ],
   "source": [
    "vgg = vgg16.VGG16(weights='imagenet', include_top=False,pooling='avg')\n",
    "X_train_vgg16 = vgg.predict(vgg16.preprocess_input(X_train),verbose=1,batch_size=1)\n",
    "X_test_vgg16 = vgg.predict(vgg16.preprocess_input(X_test),verbose=1,batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 1.000000\n",
      "Test Accuracy: 0.938000\n",
      "Confusion Matrix:\n",
      " [[94  0  0  0  0  6  0  0]\n",
      " [ 0 95  0  0  2  3  0  0]\n",
      " [ 0  0 97  0  0  1  2  0]\n",
      " [ 0  0  1 88  0  0  6  5]\n",
      " [ 0  1  0  0 96  3  0  0]\n",
      " [ 8  2  0  0  2 88  0  0]\n",
      " [ 0  0  1  3  0  0 95  1]\n",
      " [ 0  0  0  3  0  0  0 97]]\n"
     ]
    }
   ],
   "source": [
    "model = SVC(C=1,kernel='linear')\n",
    "model.fit(X_train_vgg16,y_train)\n",
    "get_scores(model,X_train_vgg16,y_train,X_test_vgg16,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graduate Points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "up to 10 points: Use “soft assignment” to assign visual words to histogram bins. Each visual word will cast a distance-weighted vote to multiple bins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vis_bow_soft(train_sifts,test_sifts,n_components=100):\n",
    "    stacked_train_sifts = np.vstack(train_sifts)\n",
    "    stacked_test_sifts = np.vstack(test_sifts)\n",
    "    gmm = GaussianMixture(n_components=n_components)\n",
    "    gmm.fit(stacked_train_sifts)\n",
    "    train_clusters = [gmm.predict_proba(words) for words in train_sifts] # word is now a vector...must change\n",
    "    X_train_bow = np.array([np.bincount(words, minlength=n_clusters) for words in train_clusters])\n",
    "    test_clusters = [gmm.predict_proba(words) for words in test_sifts]\n",
    "    X_test_bow = np.array([np.bincount(words, minlength=n_clusters) for words in test_clusters])\n",
    "    return X_train_bow,X_test_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_soft,X_test_soft = vis_bow_soft(train_sifts,test_sifts,n_clusters=100)\n",
    "model = SVC(C=.001,kernel='linear')\n",
    "model.fit(X_train_soft,y_train)\n",
    "get_scores(model,X_train_soft,y_train,X_test_soft,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "up to 10 points: Implement one of the advanced feature encoding, e.g. fisher vector encoding, super vector, or LLC. See The devil is in the details: an evaluation of recent feature encoding methods, BMVC 2011 for more details. Compare the results with that from (C). You can use built-in Gaussian mixture models in MATLAB if you want to implement the fisher vector encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# too much work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "up to 10 points: For bag of visual word models, experiment with different number of visual word, e.g. K = 25, 50, 100, 200, 400, 800, 1600. Report the categorization accuracy for each K."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.583000\n",
      "Test Accuracy: 0.505000\n",
      "Confusion Matrix:\n",
      " [[58  1 14  1  7 14  1  4]\n",
      " [ 0 83  0  3  5  2  5  2]\n",
      " [40  0 25  7  7 18  2  1]\n",
      " [ 0  6  3 51  3  6  7 24]\n",
      " [ 6  2  2  1 47 25  7 10]\n",
      " [17  4  4  4 19 44  1  7]\n",
      " [ 0  8  1 17  9  6 44 15]\n",
      " [ 3  3  3  8 13 13  5 52]]\n"
     ]
    }
   ],
   "source": [
    "X_train_bow,X_test_bow = vis_bow(train_sifts,test_sifts,n_clusters=25)\n",
    "model = SVC(C=.001,kernel='linear')\n",
    "model.fit(X_train_bow,y_train)\n",
    "get_scores(model,X_train_bow,y_train,X_test_bow,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.658000\n",
      "Test Accuracy: 0.575000\n",
      "Confusion Matrix:\n",
      " [[59  0 13  0  9 15  2  2]\n",
      " [ 0 86  0  1  7  2  4  0]\n",
      " [35  0 27  3  8 18  4  5]\n",
      " [ 1  6  1 63  1  5  7 16]\n",
      " [ 3  3  1  0 64 22  4  3]\n",
      " [16  1  7  1 17 51  3  4]\n",
      " [ 0  8  0 11 17  4 49 11]\n",
      " [ 3  1  2 12  8  6  7 61]]\n"
     ]
    }
   ],
   "source": [
    "X_train_bow,X_test_bow = vis_bow(train_sifts,test_sifts,n_clusters=50)\n",
    "model = SVC(C=.001,kernel='linear')\n",
    "model.fit(X_train_bow,y_train)\n",
    "get_scores(model,X_train_bow,y_train,X_test_bow,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.700000\n",
      "Test Accuracy: 0.610000\n",
      "Confusion Matrix:\n",
      " [[65  0  7  0 10 13  1  4]\n",
      " [ 0 85  0  2  9  1  3  0]\n",
      " [33  0 35  2  7 12  8  3]\n",
      " [ 1  6  2 57  0  5  7 22]\n",
      " [ 4  2  1  0 66 18  6  3]\n",
      " [17  2  1  0 15 63  1  1]\n",
      " [ 1  5  0  7 14  7 55 11]\n",
      " [ 1  2  3 10 11  7  4 62]]\n"
     ]
    }
   ],
   "source": [
    "X_train_bow,X_test_bow = vis_bow(train_sifts,test_sifts,n_clusters=100)\n",
    "model = SVC(C=.001,kernel='linear')\n",
    "model.fit(X_train_bow,y_train)\n",
    "get_scores(model,X_train_bow,y_train,X_test_bow,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.757000\n",
      "Test Accuracy: 0.640000\n",
      "Confusion Matrix:\n",
      " [[70  0  6  0  7 13  3  1]\n",
      " [ 0 85  0  0  7  3  4  1]\n",
      " [38  0 30  5 12 11  2  2]\n",
      " [ 1  2  0 69  3  4  7 14]\n",
      " [ 3  3  1  0 74 17  1  1]\n",
      " [17  4  3  1 16 58  1  0]\n",
      " [ 0  4  2  8 10  4 62 10]\n",
      " [ 0  1  3 14 11  2  5 64]]\n"
     ]
    }
   ],
   "source": [
    "X_train_bow,X_test_bow = vis_bow(train_sifts,test_sifts,n_clusters=200)\n",
    "model = SVC(C=.001,kernel='linear')\n",
    "model.fit(X_train_bow,y_train)\n",
    "get_scores(model,X_train_bow,y_train,X_test_bow,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.798000\n",
      "Test Accuracy: 0.651000\n",
      "Confusion Matrix:\n",
      " [[71  0  4  0  7 16  1  1]\n",
      " [ 0 88  0  0  7  2  3  0]\n",
      " [38  0 30  3  7 17  4  1]\n",
      " [ 2  4  1 62  0  4  8 19]\n",
      " [ 4  3  1  0 75 15  2  0]\n",
      " [13  2  1  1 14 66  1  2]\n",
      " [ 2  3  0  7 12  5 61 10]\n",
      " [ 2  0  4  8  7  6  5 68]]\n"
     ]
    }
   ],
   "source": [
    "X_train_bow,X_test_bow = vis_bow(train_sifts,test_sifts,n_clusters=400)\n",
    "model = SVC(C=.001,kernel='linear')\n",
    "model.fit(X_train_bow,y_train)\n",
    "get_scores(model,X_train_bow,y_train,X_test_bow,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.818000\n",
      "Test Accuracy: 0.654000\n",
      "Confusion Matrix:\n",
      " [[74  0  4  0  6 15  1  0]\n",
      " [ 0 84  0  0 10  4  2  0]\n",
      " [38  0 28  1  7 18  6  2]\n",
      " [ 2  1  0 68  1  5  8 15]\n",
      " [ 3  4  1  0 69 22  1  0]\n",
      " [18  1  0  0 12 68  1  0]\n",
      " [ 0  3  0  5 13  5 62 12]\n",
      " [ 6  0  2  9  5  5  3 70]]\n"
     ]
    }
   ],
   "source": [
    "X_train_bow,X_test_bow = vis_bow(train_sifts,test_sifts,n_clusters=800)\n",
    "model = SVC(C=.001,kernel='linear')\n",
    "model.fit(X_train_bow,y_train)\n",
    "get_scores(model,X_train_bow,y_train,X_test_bow,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "up to 10 points: Try using two different pre-trained CNN models. Report the accuracy of each of the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1888/1888 [==============================] - 557s 295ms/step\n",
      "800/800 [==============================] - 233s 292ms/step\n",
      "Training Accuracy: 1.000000\n",
      "Test Accuracy: 0.961000\n",
      "Confusion Matrix:\n",
      " [[97  0  1  0  0  2  0  0]\n",
      " [ 0 97  0  0  1  2  0  0]\n",
      " [ 0  0 98  0  0  0  2  0]\n",
      " [ 0  0  0 92  0  0  5  3]\n",
      " [ 0  0  0  0 99  1  0  0]\n",
      " [ 4  2  0  0  2 92  0  0]\n",
      " [ 0  0  1  2  0  0 97  0]\n",
      " [ 0  0  0  3  0  0  0 97]]\n"
     ]
    }
   ],
   "source": [
    "resnet = resnet50.ResNet50(weights='imagenet',include_top=False,pooling='avg')\n",
    "X_train_resnet50 = resnet.predict(resnet50.preprocess_input(X_train),verbose=1,batch_size=1)\n",
    "X_test_resnet50 = resnet.predict(resnet50.preprocess_input(X_test),verbose=1,batch_size=1)\n",
    "\n",
    "model = SVC(C=1,kernel='linear')\n",
    "model.fit(X_train_resnet50,y_train)\n",
    "get_scores(model,X_train_resnet50,y_train,X_test_resnet50,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1888/1888 [==============================] - 340s 180ms/step\n",
      "800/800 [==============================] - 141s 176ms/step\n",
      "Training Accuracy: 1.000000\n",
      "Test Accuracy: 0.930000\n",
      "Confusion Matrix:\n",
      " [[95  0  0  0  0  5  0  0]\n",
      " [ 1 89  0  0  4  5  0  1]\n",
      " [ 1  0 93  0  0  0  4  2]\n",
      " [ 0  0  2 89  0  0  6  3]\n",
      " [ 0  0  0  0 97  3  0  0]\n",
      " [ 5  1  2  0  0 92  0  0]\n",
      " [ 0  0  1  4  0  0 93  2]\n",
      " [ 0  0  0  1  0  1  2 96]]\n"
     ]
    }
   ],
   "source": [
    "inception = inception_v3.InceptionV3(weights='imagenet',include_top=False,pooling='avg')\n",
    "X_train_inception = inception.predict(inception_v3.preprocess_input(X_train),verbose=1,batch_size=1)\n",
    "X_test_inception = inception.predict(inception_v3.preprocess_input(X_test),verbose=1,batch_size=1)\n",
    "\n",
    "model = SVC(C=1,kernel='linear')\n",
    "model.fit(X_train_inception,y_train)\n",
    "get_scores(model,X_train_inception,y_train,X_test_inception,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "up to 10 points: For one specific CNN model (e.g., AlexNet or VGGNet), report the classification accuracy when you use different levels of feature activations, e.g., Pool4, Pool5, Fc6, Fc7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_resized = np.array([resize(image,(224,224),anti_aliasing=True) for image in X_train])\n",
    "X_test_resized = np.array([resize(image,(224,224),anti_aliasing=True) for image in X_test])\n",
    "vgg = vgg16.VGG16(weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1888/1888 [==============================] - 311s 165ms/step\n",
      "800/800 [==============================] - 129s 162ms/step\n",
      "Training Accuracy: 1.000000\n",
      "Test Accuracy: 0.741000\n",
      "Confusion Matrix:\n",
      " [[69  2  6  0  2 21  0  0]\n",
      " [ 0 87  0  1  8  4  0  0]\n",
      " [15  1 65  4  2 10  2  1]\n",
      " [ 4  0  0 69  1  2  8 16]\n",
      " [ 6  5  3  0 71  8  4  3]\n",
      " [18  2  3  0  7 69  1  0]\n",
      " [ 0  1  5  4  5  1 84  0]\n",
      " [ 3  0  1  7  5  1  4 79]]\n"
     ]
    }
   ],
   "source": [
    "cnn = Model(inputs=vgg.input,outputs=vgg.get_layer('block3_pool').output)\n",
    "X_train_cnn = cnn.predict(vgg16.preprocess_input(X_train_resized),verbose=1,batch_size=1).reshape(len(X_train),-1)\n",
    "X_test_cnn = cnn.predict(vgg16.preprocess_input(X_test_resized),verbose=1,batch_size=1).reshape(len(X_test),-1)\n",
    "\n",
    "model = SVC(C=1,kernel='linear')\n",
    "model.fit(X_train_cnn,y_train)\n",
    "get_scores(model,X_train_cnn,y_train,X_test_cnn,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1888/1888 [==============================] - 430s 228ms/step\n",
      "800/800 [==============================] - 191s 238ms/step\n",
      "Training Accuracy: 1.000000\n",
      "Test Accuracy: 0.710000\n",
      "Confusion Matrix:\n",
      " [[69  1  4  1  2 23  0  0]\n",
      " [ 0 83  0  3  8  5  0  1]\n",
      " [15  2 68  6  3  6  0  0]\n",
      " [ 2  2  0 67  1  3 11 14]\n",
      " [ 7  5  3  1 60 16  4  4]\n",
      " [16  3  5  0  7 68  1  0]\n",
      " [ 0  1  4 10  5  1 77  2]\n",
      " [ 0  3  0 10  7  1  3 76]]\n"
     ]
    }
   ],
   "source": [
    "cnn = Model(inputs=vgg.input,outputs=vgg.get_layer('block4_pool').output)\n",
    "X_train_cnn = cnn.predict(vgg16.preprocess_input(X_train_resized),verbose=1,batch_size=1).reshape(len(X_train),-1)\n",
    "X_test_cnn = cnn.predict(vgg16.preprocess_input(X_test_resized),verbose=1,batch_size=1).reshape(len(X_test),-1)\n",
    "\n",
    "model = SVC(C=1,kernel='linear')\n",
    "model.fit(X_train_cnn,y_train)\n",
    "get_scores(model,X_train_cnn,y_train,X_test_cnn,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1888/1888 [==============================] - 452s 239ms/step\n",
      "800/800 [==============================] - 198s 247ms/step\n",
      "Training Accuracy: 0.851000\n",
      "Test Accuracy: 0.691000\n",
      "Confusion Matrix:\n",
      " [[65  1  6  3  8 17  0  0]\n",
      " [ 1 83  0  3  8  5  0  0]\n",
      " [21  1 66  5  2  4  0  1]\n",
      " [ 8  2  5 61  0  2  8 14]\n",
      " [10  2  2  2 61 19  1  3]\n",
      " [17  2  2  1  5 71  1  1]\n",
      " [ 0  3  5  9  9  0 74  0]\n",
      " [ 3  4  1  7  7  4  2 72]]\n"
     ]
    }
   ],
   "source": [
    "cnn = Model(inputs=vgg.input,outputs=vgg.get_layer('block5_pool').output)\n",
    "X_train_cnn = cnn.predict(vgg16.preprocess_input(X_train_resized),verbose=1,batch_size=1).reshape(len(X_train),-1)\n",
    "X_test_cnn = cnn.predict(vgg16.preprocess_input(X_test_resized),verbose=1,batch_size=1).reshape(len(X_test),-1)\n",
    "\n",
    "model = SVC(C=1,kernel='linear')\n",
    "model.fit(X_train_cnn,y_train)\n",
    "get_scores(model,X_train_cnn,y_train,X_test_cnn,y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
