{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scene Categorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import re\n",
    "import time\n",
    "from imageio import imread\n",
    "from pathlib import Path\n",
    "from scipy.io import loadmat\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.cluster import KMeans,MiniBatchKMeans\n",
    "from sklearn.neighbors import KDTree, KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.applications import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_sort(value):\n",
    "    numbers = re.compile(r'(\\d+)')\n",
    "    value = str(value)\n",
    "    parts = numbers.split(value)\n",
    "    parts[1::2] = map(int, parts[1::2])\n",
    "    return parts\n",
    "\n",
    "def get_images():\n",
    "    train_path = Path('./data/train')\n",
    "    test_path = Path('./data/test')\n",
    "    X_train = []\n",
    "    X_test = []\n",
    "    for image_path in sorted(train_path.glob('*.jpg'),key=numerical_sort):\n",
    "        image = imread(image_path)\n",
    "        X_train.append(image)\n",
    "    for image_path in sorted(test_path.glob('*.jpg'),key=numerical_sort):\n",
    "        image = imread(image_path)\n",
    "        X_test.append(image)\n",
    "    X_train = np.array(X_train)\n",
    "    X_test = np.array(X_test)\n",
    "    return X_train,X_test\n",
    "\n",
    "def get_labels():\n",
    "    label_path = Path('./data/gs.mat')\n",
    "    labels = loadmat(label_path)\n",
    "    y_train = labels['train_gs'].flatten()\n",
    "    y_test = labels['test_gs'].flatten()\n",
    "    return y_train,y_test\n",
    "\n",
    "def histogram_distance(h1,h2):\n",
    "    h1 = h1.astype(np.float32)\n",
    "    h2 = h2.astype(np.float32)\n",
    "    method = cv2.HISTCMP_INTERSECT\n",
    "    return cv2.compareHist(h1,h2,method)\n",
    "\n",
    "def get_scores(model,X_train,y_train,X_test,y_test):\n",
    "    yhat = model.predict(X_train)\n",
    "    score = accuracy_score(y_train,yhat)\n",
    "    print('Training Accuracy: %f' % round(score,3))    \n",
    "    yhat = model.predict(X_test)\n",
    "    score = accuracy_score(y_test,yhat)\n",
    "    print('Test Accuracy: %f' % round(score,3))\n",
    "    print('Confusion Matrix:\\n', confusion_matrix(y_test,yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test = get_images()\n",
    "print('training data size:',X_train.shape)\n",
    "print('test data size:',X_test.shape)\n",
    "\n",
    "y_train,y_test = get_labels()\n",
    "print('training label size:',y_train.shape)\n",
    "print('test label size:',y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Color histogram and kNN classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_color_hists(X_train,X_test,bins=10):\n",
    "    X_train_hist = np.zeros((len(X_train),bins*3))\n",
    "    X_test_hist = np.zeros((len(X_test),bins*3))\n",
    "    for i in range(len(X_train)):\n",
    "        red = cv2.calcHist([X_train[i,:,:,0]],[0],None,[bins],[0,256]).flatten()\n",
    "        green = cv2.calcHist([X_train[i,:,:,1]],[0],None,[bins],[0,256]).flatten()\n",
    "        blue = cv2.calcHist([X_train[i,:,:,2]],[0],None,[bins],[0,256]).flatten()\n",
    "        X_train_hist[i] = np.concatenate([red,green,blue])\n",
    "    for i in range(len(X_test)):\n",
    "        red = cv2.calcHist([X_test[i,:,:,0]],[0],None,[bins],[0,256]).flatten()\n",
    "        green = cv2.calcHist([X_test[i,:,:,1]],[0],None,[bins],[0,256]).flatten()\n",
    "        blue = cv2.calcHist([X_test[i,:,:,2]],[0],None,[bins],[0,256]).flatten()\n",
    "        X_test_hist[i] = np.concatenate([red,green,blue])\n",
    "    return X_train_hist,X_test_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_hist,X_test_hist = get_color_hists(X_train,X_test,bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KNeighborsClassifier(n_neighbors=10,n_jobs=-1)\n",
    "model.fit(X_train_hist,y_train)\n",
    "get_scores(model,X_train_hist,y_train,X_test_hist,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of visual words model and nearest neighbor classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sift():\n",
    "    sift_path = Path('./data/sift_desc.mat')\n",
    "    sift = loadmat(sift_path)\n",
    "    train = sift['train_D'].flatten()\n",
    "    test = sift['test_D'].flatten()\n",
    "    train_sifts = [t.T for t in train]\n",
    "    test_sifts = [t.T for t in test]\n",
    "    return train_sifts,test_sifts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sifts,test_sifts = get_sift()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vis_bow(train_sifts,test_sifts,n_clusters=100):\n",
    "    stacked_train_sifts = np.vstack(train_sifts)\n",
    "    stacked_test_sifts = np.vstack(test_sifts)\n",
    "    kmeans = MiniBatchKMeans(n_clusters=n_clusters)\n",
    "    kmeans.fit(stacked_train_sifts)\n",
    "    train_clusters = [kmeans.predict(words) for words in train_sifts]\n",
    "    X_train_bow = np.array([np.bincount(words, minlength=n_clusters) for words in train_clusters])\n",
    "    test_clusters = [kmeans.predict(words) for words in test_sifts]\n",
    "    X_test_bow = np.array([np.bincount(words, minlength=n_clusters) for words in test_clusters])\n",
    "    return X_train_bow,X_test_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_bow,X_test_bow = vis_bow(train_sifts,test_sifts,n_clusters=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KNeighborsClassifier(n_neighbors=15,n_jobs=-1)\n",
    "model.fit(X_train_bow,y_train)\n",
    "get_scores(model,X_train_bow,y_train,X_test_bow,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of visual words model and a discriminative classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.clock()\n",
    "model = SVC(C=.001,kernel='linear')\n",
    "model.fit(X_train_bow,y_train)\n",
    "end = time.clock()\n",
    "print('training time:',round(end-start,3),'seconds')\n",
    "\n",
    "start = time.clock()\n",
    "get_scores(model,X_train_bow,y_train,X_test_bow,y_test)\n",
    "end = time.clock()\n",
    "print('testing time:',round(end-start,3),'seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN model and a discriminative classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = vgg16.VGG16(weights='imagenet', include_top=False)\n",
    "X_train_encoding = model.predict(vgg16.preprocess_input(X_train),verbose=1,batch_size=32)\n",
    "#X_test_encoding = model.predict(vgg16.preprocess_input(X_test),verbose=1,batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_encoding.shape,X_test_encoding.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graduate Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?model.predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
